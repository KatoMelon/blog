<!doctype html><html lang=zh dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="课程第三周PPT及教程答案知识点整理，完成于12.18"><title>人工智能导论 - Week3概念整理</title>
<link rel=canonical href=https://katomelon.github.io/blog/p/intro-to-ai-w3/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="人工智能导论 - Week3概念整理"><meta property='og:description' content="课程第三周PPT及教程答案知识点整理，完成于12.18"><meta property='og:url' content='https://katomelon.github.io/blog/p/intro-to-ai-w3/'><meta property='og:site_name' content="KatMelon's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='人工智能导论'><meta property='article:published_time' content='2023-12-18T00:00:00+00:00'><meta property='article:modified_time' content='2023-12-18T00:00:00+00:00'><meta name=twitter:title content="人工智能导论 - Week3概念整理"><meta name=twitter:description content="课程第三周PPT及教程答案知识点整理，完成于12.18"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_ba03ba61d53929d4.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>😙</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>KatMelon's Blog</a></h1><h2 class=site-description>继续精进.</h2></div></header><ol class=menu-social><li><a href=https://github.com/KatoMelon target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/blog/%E5%85%B3%E4%BA%8E/><svg class="icon icon-tabler icon-tabler-info-circle" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 12a9 9 0 1018 0A9 9 0 003 12"/><path d="M12 9h.01"/><path d="M11 12h1v4h1"/></svg>
<span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#本章>本章</a></li><li><a href=#所有知识点>所有知识点</a><ol><li><a href=#scikit-learn>scikit-learn</a></li><li><a href=#tensor-张量>Tensor 张量</a></li><li><a href=#gpu与深度学习>GPU与深度学习</a></li><li><a href=#tensorflow>TensorFlow</a></li><li><a href=#static-graph--dynamic-graph>Static Graph & Dynamic Graph</a></li><li><a href=#pytorch>PyTorch</a></li><li><a href=#brief-history-of-computer-vision>Brief History of Computer Vision</a></li><li><a href=#human-vision-人类视觉>Human Vision 人类视觉</a></li><li><a href=#computer-vision-计算机视觉>Computer Vision 计算机视觉</a></li><li><a href=#image-图像>Image 图像</a></li><li><a href=#main-goal-of-computer-vision>Main Goal of Computer Vision</a></li><li><a href=#computer-vision-techniques>Computer Vision Techniques</a></li><li><a href=#convolution-卷积>Convolution 卷积</a></li><li><a href=#kernel-卷积核>Kernel 卷积核</a></li><li><a href=#stride-步幅>Stride 步幅</a></li><li><a href=#padding-填充>Padding 填充</a></li><li><a href=#channel-通道>Channel 通道</a></li><li><a href=#卷积的计算>卷积的计算</a></li><li><a href=#de-convolution-反卷积>De-convolution 反卷积</a></li><li><a href=#dilatedatrous-convolution-膨胀卷积>Dilated/Atrous Convolution 膨胀卷积</a></li><li><a href=#pooling-池化>Pooling 池化</a></li><li><a href=#flatten-压平>Flatten 压平</a></li><li><a href=#fully-connect--dropout>Fully Connect & Dropout</a></li><li><a href=#normalization-正交化归一化>Normalization 正交化/归一化</a></li><li><a href=#feature-extraction-特征提取>Feature extraction 特征提取</a></li><li><a href=#image-classification-图像分类>Image Classification 图像分类</a></li><li><a href=#steps-to-build-a-computer-vision-model>Steps to build a computer vision model</a></li><li><a href=#deep-learning-based-image-classification>Deep Learning based Image Classification</a></li><li><a href=#performance-metrics-性能指标>Performance Metrics 性能指标</a></li><li><a href=#confusion-matrix-混淆矩阵>Confusion Matrix 混淆矩阵</a></li><li><a href=#segmentation-分割>Segmentation 分割</a></li><li><a href=#object-recognition-物体识别>Object Recognition 物体识别</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AF%BE%E4%B8%9A/ style=background-color:#2a9d8f;color:#fff>课业</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/intro-to-ai-w3/>人工智能导论 - Week3概念整理</a></h2><h3 class=article-subtitle>课程第三周PPT及教程答案知识点整理，完成于12.18</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Dec 18, 2023</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 6 分钟</time></div></footer></div></header><section class=article-content><p><img src=https://badges.toozhao.com/badges/01HJ3GGQ6MR66VM70BVZS4SSVX/green.svg loading=lazy alt="Page Views Count"></p><h2 id=本章>本章</h2><p>分两个主要部分：实用AI工具和计算机视觉。前一部分介绍一些框架和工具，内容不多，后一部分介绍计算机视觉，占大头。</p><p>此文档整理总结Week3 Slide中的定义和知识点。</p><h2 id=所有知识点>所有知识点</h2><p>按PPT内顺序排列。列出PPT和tutorial中所有概念的英文原始释义（若有）和中文翻译，方便背诵。</p><hr><h3 id=scikit-learn>scikit-learn</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>scikit-learn</td><td>PPT p5-p13</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Simple and efficient tools for predictive data analysis</th></tr></thead><tbody><tr><td>译</td><td>用于预测数据分析的简单有效的工具</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>开源免费可商用的数据分析工具，对所有人可用，不限制训练框架（Tensorflow. Pytorch等），支持机器学习方法，数据处理，可视化，基于Numpy、SciPy、matplotlib等库。<br>提供分类Classification、回归Regression、聚类Clustering等工具。课件中给出了一些实际的例子。</td></tr></tbody></table></div><hr><h3 id=tensor-张量>Tensor 张量</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Tensor 张量</td><td>PPT p14</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>In deep learning frameworks, they use specialized data structure called Tensor.</th></tr></thead><tbody><tr><td>译</td><td>在深度学习框架中，使用称为张量的专用数据结构。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>张量的本质是多维数组（Multidimensional Array）。例如，0阶张量的本质是一个实数或复数，一阶张量是一个矢量，二阶张量是一个矩阵，更高阶数的张量类似，例如三阶张量表示立方体中的数等等。<br><img src=/blog/p/intro-to-ai-w3/image/image_oQhIsU2aXR.png width=569 height=411 srcset="/blog/p/intro-to-ai-w3/image/image_oQhIsU2aXR_hu_74e8b4e8a12df3f8.png 480w, /blog/p/intro-to-ai-w3/image/image_oQhIsU2aXR_hu_977c07a7ba22db2b.png 1024w" loading=lazy alt=img class=gallery-image data-flex-grow=138 data-flex-basis=332px></td></tr></tbody></table></div><hr><h3 id=gpu与深度学习>GPU与深度学习</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>GPU与深度学习</td><td>PPT p16</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Deep learning relies on GPUs.</th></tr></thead><tbody><tr><td>译</td><td>深度学习依赖于GPU</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>严格来说这说法不准确，深度学习依赖密集计算，只不过是跟CPU一比GPU刚好能干这活。GPU毕竟还是专搞图形计算的。<br><img src=/blog/p/intro-to-ai-w3/image/image_qtOtKSEPF1.png width=1210 height=583 srcset="/blog/p/intro-to-ai-w3/image/image_qtOtKSEPF1_hu_37892f4b588ff198.png 480w, /blog/p/intro-to-ai-w3/image/image_qtOtKSEPF1_hu_49fed75410e48c91.png 1024w" loading=lazy class=gallery-image data-flex-grow=207 data-flex-basis=498px><br>CPU适用于复杂逻辑控制，例如武器装备，IT等场景；GPU适用于密码学、挖矿、图形计算等需要平行计算的场景。CPU耗能小，GPU耗能高。</td></tr></tbody></table></div><hr><h3 id=tensorflow>TensorFlow</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>TensorFlow</td><td>PPT p14-p17</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>An open-source Deep Learning library</th></tr></thead><tbody><tr><td>译</td><td>一款开源的深度学习库</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>由谷歌贡献。其训练流程：<img src=/blog/p/intro-to-ai-w3/image/image_Y5yFIP1sSR.png width=1392 height=495 srcset="/blog/p/intro-to-ai-w3/image/image_Y5yFIP1sSR_hu_c27367668e383334.png 480w, /blog/p/intro-to-ai-w3/image/image_Y5yFIP1sSR_hu_5904433df1aa5769.png 1024w" loading=lazy class=gallery-image data-flex-grow=281 data-flex-basis=674px>其编程模型可将数字计算（Numeric Computation）过程表达为图表。图表节点为带有数字输入输出的操作，图表的边缘为节点间流动着的张量。<img src=/blog/p/intro-to-ai-w3/image/image_65pfTsx9M9.png width=790 height=340 srcset="/blog/p/intro-to-ai-w3/image/image_65pfTsx9M9_hu_80ccf82384f70953.png 480w, /blog/p/intro-to-ai-w3/image/image_65pfTsx9M9_hu_32c6d6c2552420cd.png 1024w" loading=lazy class=gallery-image data-flex-grow=232 data-flex-basis=557px></td></tr></tbody></table></div><hr><h3 id=static-graph--dynamic-graph>Static Graph & Dynamic Graph</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Static Graph & Dynamic Graph</td><td>PPT p20 & Tutorial Q1</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>The computation process can be view as a graph.</th></tr></thead><tbody><tr><td>译</td><td>计算过程可展示为图表</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>A static graph is one that defines the entire computation graph before performing the computation. When the data is obtained, it is calculated according to the defined calculation graph.</th></tr></thead><tbody><tr><td>译</td><td>静态图是在执行计算之前定义整个计算图的图。获得数据后，根据定义的计算图进行计算。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Dynamic graphs, on the other hand, generate computational graphs as they are computed, and the complete graph is known only when the computation is completed.</th></tr></thead><tbody><tr><td>译</td><td>动态图在计算时生成计算图，并且只有在计算完成时才能得到完整的图表。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_r4OF0m_SwR.png width=1321 height=536 srcset="/blog/p/intro-to-ai-w3/image/image_r4OF0m_SwR_hu_a3913d16b98332c8.png 480w, /blog/p/intro-to-ai-w3/image/image_r4OF0m_SwR_hu_3eab25e77be4f958.png 1024w" loading=lazy class=gallery-image data-flex-grow=246 data-flex-basis=591px></td></tr></tbody></table></div><hr><h3 id=pytorch>PyTorch</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Pytorch</td><td>PPT p22</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Open-source machine learning library</th></tr></thead><tbody><tr><td>译</td><td>开源的机器学习库</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>由Fackbook AI研究实验室维护，依靠GPU能力，自动计算梯度，更容易测试和开发新产品。<br>优点有：类Python（Pythonic）设计理念，简洁；自动计算梯度（Autograd）；有许多已实现好的算法和组件。</td></tr></tbody></table></div><hr><h3 id=brief-history-of-computer-vision>Brief History of Computer Vision</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Brief History of Computer Vision</td><td>PPT p31</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_0fPhtYtABy.png width=945 height=670 srcset="/blog/p/intro-to-ai-w3/image/image_0fPhtYtABy_hu_28be9f54f338390a.png 480w, /blog/p/intro-to-ai-w3/image/image_0fPhtYtABy_hu_485deab6c27a587b.png 1024w" loading=lazy class=gallery-image data-flex-grow=141 data-flex-basis=338px></td></tr></tbody></table></div><hr><h3 id=human-vision-人类视觉>Human Vision 人类视觉</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Human Vision 人类视觉</td><td>PPT p42</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Vision is the process of discovering what is present in the world and where it is by looking</th></tr></thead><tbody><tr><td>译</td><td>视觉是通过观察发现世界上存在什么以及它在哪里的过程</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_tbdQfvMkKl.png width=738 height=199 srcset="/blog/p/intro-to-ai-w3/image/image_tbdQfvMkKl_hu_f8d5e0feb9c88f8e.png 480w, /blog/p/intro-to-ai-w3/image/image_tbdQfvMkKl_hu_5db7c7a2c1beb2e9.png 1024w" loading=lazy class=gallery-image data-flex-grow=370 data-flex-basis=890px></td></tr></tbody></table></div><hr><h3 id=computer-vision-计算机视觉>Computer Vision 计算机视觉</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Computer Vision 计算机视觉</td><td>PPT p42</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Computer Vision is the study of analysis of pictures and videos in order to achieve results similar to those as by humans</th></tr></thead><tbody><tr><td>译</td><td>计算机视觉是一门对图片和视频进行分析的研究，目的是为了获得与人类（视觉）类似的结果</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_kqipoAXa5_.png width=1159 height=337 srcset="/blog/p/intro-to-ai-w3/image/image_kqipoAXa5__hu_c353dce14f666649.png 480w, /blog/p/intro-to-ai-w3/image/image_kqipoAXa5__hu_20ec47de362d649.png 1024w" loading=lazy class=gallery-image data-flex-grow=343 data-flex-basis=825px></td></tr></tbody></table></div><hr><h3 id=image-图像>Image 图像</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Image 图像</td><td>PPT p44</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>An image is a rectangular grid of data of light values</th></tr></thead><tbody><tr><td>译</td><td>图像是光值（亮度值）数据的矩形网格</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>此处给出的定义在PPT中指代灰度图像，更严格的定义应该是<br>图像是像素的矩阵网格。像素的值可以是二进制、灰度、颜色或多模态等。（见PPT p48）</td></tr></tbody></table></div><hr><h3 id=main-goal-of-computer-vision>Main Goal of Computer Vision</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Main Goal of Computer Vision</td><td>PPT p64</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Need for an algorithm that can write the rules for us so that we don’t have to write it by hand.</th></tr></thead><tbody><tr><td>译</td><td>需要一种可以自己寻找规则的算法，这样就无需手动编写了。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Instead of creating object models, hundreds of thousands of pictures were collected from the internet and an algorithm was used.</th></tr></thead><tbody><tr><td>译</td><td>不创建具体的模型，而是从网络上收集大量图片，使用算法（来学习规则）</td></tr></tbody></table></div><hr><h3 id=computer-vision-techniques>Computer Vision Techniques</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Computer Vision Techniques</td><td>PPT p67</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Classification, Semantic Segmentation, Object Detection, Instance Segmentation</th></tr></thead><tbody><tr><td>译</td><td>分类，语义分割，目标检测，实例分割</td></tr></tbody></table></div><hr><h3 id=convolution-卷积>Convolution 卷积</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Convolution 卷积</td><td>PPT p69</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>Problems in processing images with fully connected networks：<br>全连接网络图像处理中的问题:<br>Too many parameters in the weight matrix -> overfitting<br>权重矩阵中参数太多->过拟合<br>Convolutional neural network solution<br>卷积神经网络解决方案<br>Local correlation, parameter sharing<br>本地关联，参数共享<br><br><strong>卷积的四个基本属性（Basic Properties）：</strong><br>卷积核（Kernel）、步幅（Stride）、填充（Padding）、通道（Channel）。<img src=/blog/p/intro-to-ai-w3/image/image_XI4OaZT-iQ.png width=1050 height=606 srcset="/blog/p/intro-to-ai-w3/image/image_XI4OaZT-iQ_hu_3c84f74f35cdf9f.png 480w, /blog/p/intro-to-ai-w3/image/image_XI4OaZT-iQ_hu_590ee896d20ed094.png 1024w" loading=lazy class=gallery-image data-flex-grow=173 data-flex-basis=415px></td></tr></tbody></table></div><hr><h3 id=kernel-卷积核>Kernel 卷积核</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Kernel 卷积核</td><td>PPT p71</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Kernel: also known as receptive field, the sense of convolution operation, intuitively understood as a filter matrix, commonly used convolution kernel size of 3 × 3, 5 × 5 and so on;</th></tr></thead><tbody><tr><td>译</td><td>卷积核：也称感受野，是卷积操作的核心。直观地理解为一个滤波器矩阵，常用的卷积核尺寸有3×3、5×5等。</td></tr></tbody></table></div><hr><h3 id=stride-步幅>Stride 步幅</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Stride 步幅</td><td>PPT p71</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Stride: the pixels moved by the convolution kernel at each step when traversing the feature map</th></tr></thead><tbody><tr><td>译</td><td>步幅：在遍历特征图时，卷积核在每一步移动的像素数。步幅决定了卷积操作对输入的采样间隔。</td></tr></tbody></table></div><hr><h3 id=padding-填充>Padding 填充</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Padding 填充</td><td>PPT p71</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Padding: the way to deal with the boundary of the feature map. To fill the boundary (generally filled with 0), and then perform the convolution operation, which will make the size of the output feature map the same as the size of the input feature map;</th></tr></thead><tbody><tr><td>译</td><td>填充：处理特征图边界的方法。通过在特征图边界填充（通常使用0进行填充），然后进行卷积操作，可以使输出特征图的大小与输入特征图相同。填充有助于保持特征图边缘信息。</td></tr></tbody></table></div><hr><h3 id=channel-通道>Channel 通道</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Channel 通道</td><td>PPT p71</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Channel: the number of channels (layers) of the convolution layer.</th></tr></thead><tbody><tr><td>译</td><td>通道：卷积层的通道（层）数</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>每个通道对输入进行一种特定的卷积操作，多个通道的输出叠加形成最终的输出特征图。</td></tr></tbody></table></div><hr><h3 id=卷积的计算>卷积的计算</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>卷积的计算</td><td>PPT p74-p83<br>Tutorial Solution Q4 & Q5</td></tr></tbody></table></div><p>详见专题子页面：(WIP)</p><hr><h3 id=de-convolution-反卷积>De-convolution 反卷积</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>De-convolution 反卷积</td><td>PPT p84</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Equivalent to a transposition computation after converting a convolution kernel to a sparse matrix</th></tr></thead><tbody><tr><td>译</td><td>相当于将卷积核转换为稀疏矩阵后的转置计算</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>卷积是把图片弄成特征图，反卷积是把特征图弄成图片</td></tr></tbody></table></div><hr><h3 id=dilatedatrous-convolution-膨胀卷积>Dilated/Atrous Convolution 膨胀卷积</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Dilated/Atrous Convolution 膨胀卷积</td><td>PPT p86</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>To expand the receptive field, the kernel is &ldquo;inflated&rdquo; by inserting spaces between elements inside the convolutional kernel to form a &ldquo;null convolution&rdquo; (or inflated convolution), and the kernel to be expanded is indicated by the expansion rate parameter L, i.e., L-1 spaces are inserted between the kernel elements.</th></tr></thead><tbody><tr><td>译</td><td>为了扩大感受野，卷积核通过在卷积核内的元素之间插入空白，形成一种“空洞卷积”（或膨胀卷积）。要扩展的卷积核由扩张率参数L指示，即在卷积核元素之间插入L-1个空格。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_Ds0u0blvNc.png width=871 height=349 srcset="/blog/p/intro-to-ai-w3/image/image_Ds0u0blvNc_hu_50347d17f41979fe.png 480w, /blog/p/intro-to-ai-w3/image/image_Ds0u0blvNc_hu_99e1778ed500274b.png 1024w" loading=lazy class=gallery-image data-flex-grow=249 data-flex-basis=598px></td></tr></tbody></table></div><hr><h3 id=pooling-池化>Pooling 池化</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Pooling 池化</td><td>PPT p87</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Pooling is used for regions of the image that do not overlap (this is different from the convolution operation)</th></tr></thead><tbody><tr><td>译</td><td>池化操作用于图像中不重叠的区域（与卷积操作不同）</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_KGZlrUYnBe.png width=958 height=400 srcset="/blog/p/intro-to-ai-w3/image/image_KGZlrUYnBe_hu_46d32dc10a575f8c.png 480w, /blog/p/intro-to-ai-w3/image/image_KGZlrUYnBe_hu_6e8e30d3a0bc438e.png 1024w" loading=lazy class=gallery-image data-flex-grow=239 data-flex-basis=574px></td></tr></tbody></table></div><hr><h3 id=flatten-压平>Flatten 压平</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Flatten 压平</td><td>PPT p90</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Flatten refers to the process of taking the two-dimensional feature maps produced by the convolution and pooling layers and transforming them into a one-dimensional vector.</th></tr></thead><tbody><tr><td>译</td><td>&ldquo;压平"指的是将由卷积和池化层产生的二维特征图转化为一维向量的过程。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_1UxOnPC0oc.png width=942 height=387 srcset="/blog/p/intro-to-ai-w3/image/image_1UxOnPC0oc_hu_52c5208294106997.png 480w, /blog/p/intro-to-ai-w3/image/image_1UxOnPC0oc_hu_7d43be5a508fc91b.png 1024w" loading=lazy class=gallery-image data-flex-grow=243 data-flex-basis=584px></td></tr></tbody></table></div><hr><h3 id=fully-connect--dropout>Fully Connect & Dropout</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Fully Connect & Dropout</td><td>PPT p91</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><strong>全连接（Fully Connected）</strong>：<br>将前一层的所有神经元连接到当前层的每个神经元。<br>用于在神经网络中进行分类或回归。<br><br><strong>Dropout（丢弃）</strong>：<br>在训练期间随机丢弃一部分神经元，防止网络过度依赖某些特定神经元。有助于减少过拟合并提高模型的泛化能力。</td></tr></tbody></table></div><hr><h3 id=normalization-正交化归一化>Normalization 正交化/归一化</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Normalization 正交化/归一化</td><td>PPT p92-p93</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Normalization techniques in Convolutional Neural Networks (CNNs) are crucial for improving training stability, accelerating convergence, and achieving better generalization.</th></tr></thead><tbody><tr><td>译</td><td>在卷积神经网络（CNNs）中，归一化技术对于提高训练稳定性、加速收敛速度以及实现更好的泛化效果至关重要。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_gl0Wns1Tmz.png width=970 height=331 srcset="/blog/p/intro-to-ai-w3/image/image_gl0Wns1Tmz_hu_9a96be0ae071dc53.png 480w, /blog/p/intro-to-ai-w3/image/image_gl0Wns1Tmz_hu_8103fb62547f5f33.png 1024w" loading=lazy class=gallery-image data-flex-grow=293 data-flex-basis=703px></td></tr></tbody></table></div><hr><h3 id=feature-extraction-特征提取>Feature extraction 特征提取</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Feature extraction 特征提取</td><td>PPT p93-p94</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Feature is a scalar x which is quantitatively describes a property of the Object.</th></tr></thead><tbody><tr><td>译</td><td>特征是一个标量x，定量地描述了对象的属性。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>A pattern is represented by a set of N features, or attributes, viewed as a N- dimensional feature vector.</th></tr></thead><tbody><tr><td>译</td><td>模式由一组N个特征或属性表示，这些特征或属性被视为N维特征向量。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Class is a set of patterns that share some common properties</th></tr></thead><tbody><tr><td>译</td><td>类型是拥有一些公共属性的模式的集合</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Classification is a mathematical function or algorithm which assigns a feature to one of the classes.</th></tr></thead><tbody><tr><td>译</td><td>分类是一种数学函数或算法，将一个特征分配给一个类型。</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><strong>Good features:</strong><br>Objects from the same class have similar feature values.<br>同类物体值相同<br>Objects from different classes have different values.<br>不同类物体值不同<img src=/blog/p/intro-to-ai-w3/image/image_Np_I-gygy8.png width=894 height=369 srcset="/blog/p/intro-to-ai-w3/image/image_Np_I-gygy8_hu_6031058bf85c1554.png 480w, /blog/p/intro-to-ai-w3/image/image_Np_I-gygy8_hu_2f9b367cd3f79572.png 1024w" loading=lazy class=gallery-image data-flex-grow=242 data-flex-basis=581px></td></tr></tbody></table></div><hr><h3 id=image-classification-图像分类>Image Classification 图像分类</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Image Classification 图像分类</td><td>PPT p97</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Given a set of pixels determine the category of image</th></tr></thead><tbody><tr><td>译</td><td>给定一组像素，确定该图像的类别</td></tr></tbody></table></div><hr><h3 id=steps-to-build-a-computer-vision-model>Steps to build a computer vision model</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Steps to build a computer vision model</td><td>PPT p98<br>Tutorial Solution Q2</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Data collection: Collect all possible data that is related to the goal of the model</th></tr></thead><tbody><tr><td>译</td><td>数据收集：收集与模型目标相关的所有可能的数据</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Data cleaning: Filter thecollected data and remove unclear pictures</th></tr></thead><tbody><tr><td>译</td><td>数据清理：对收集到的数据进行过滤，去除不清晰的图片</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Data preparation: Resize all the pictures to one common size</th></tr></thead><tbody><tr><td>译</td><td>数据准备：将所有图片调整为一个通用大小</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Build and train the model: Start coding</th></tr></thead><tbody><tr><td>译</td><td>构建和训练模型：开始写代码</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>classification or recognition (making sense of the visual information)</th></tr></thead><tbody><tr><td>译</td><td>分类或识别：使视觉信息有意义</td></tr></tbody></table></div><hr><h3 id=deep-learning-based-image-classification>Deep Learning based Image Classification</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Deep Learning based Image Classification</td><td>PPT p100</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><strong>Cascade of Non-linear Transformations（非线性变换的级联）</strong>：<br><strong>含义：</strong> 一系列非线性变换的级联，其中输入数据通过一系列非线性操作或转换，逐渐被映射到更高级别的表示。这在深度学习中很常见，因为深层神经网络的每一层都可以看作对输入数据的一种非线性变换。<br><br><strong>End-to-End Learning（端到端学习）</strong>：<br><strong>含义：</strong> 整个系统的学习过程，从输入直接到输出，没有人为设计的中间步骤或特征。在端到端学习中，模型尽可能地从原始输入到最终目标输出进行学习，而无需手工设计中间阶段的特征提取或转换。<br><br><strong>General Framework (Any Hierarchical Model is Deep)（通用框架，任何分层模型都是深度的）</strong>：<br><strong>含义：</strong> 深度学习中的一般性框架，其中任何具有分层结构的模型都可以被认为是深度模型。深度模型通常包含多个层次的表示学习，这使得模型能够逐渐学习数据的抽象表示。<br><br>Q：为什么需要很多层？<br>A：When input has hierarchical structure, the use of a hierarchical architecture is potentially more efficient because intermediate computations can be re-used. DL architectures are efficient also because they use distributed representations which are shared across classes.<br>当输入具有分层结构时，使用分层架构可能更有效，因为中间计算可以被重复利用。深度学习架构也是高效的，因为它们使用分布式表示，这些表示在不同类别之间是共享的。</td></tr></tbody></table></div><hr><h3 id=performance-metrics-性能指标>Performance Metrics 性能指标</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Performance Metrics 性能指标</td><td>PPT p126</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>用以评测模型的准确度和精确度。<br><br><strong>True/False Positive/Negative：</strong> 模型正确/错误预测正/负类别的数量。<br><br><strong>Precision（精确度）</strong>：TP/(TP+FP) - what percentage of the positive class is actually positive?<br>表示被模型正确分类为正类别的样本数量与模型所有预测为正类别的样本数量之比。<br><br><strong>Recall（召回率）：</strong> TP/(TP+FN) - what percentage of the positive class gets captured by the model?<br>表示实际正类别样本中被模型正确分类的数量与所有实际正类别样本的数量之比。<br><br><strong>Accuracy（准确率）：</strong>(TP+TN)/(TP+FP+TN+FN) - what percentage of predictions are correct?<br>是模型正确分类的图像数量与总图像数量之比。</td></tr></tbody></table></div><hr><h3 id=confusion-matrix-混淆矩阵>Confusion Matrix 混淆矩阵</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Confusion Matrix 混淆矩阵</td><td>PPT p128</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td>Good for checking where your model is incorrect<br>用于检查模型不正确的地方<br>For multi-class classification it reflects which classes are correlated<br>对于多类别的分类，它反映了哪些类型是相关的</td></tr></tbody></table></div><hr><h3 id=segmentation-分割>Segmentation 分割</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Segmentation 分割</td><td>PPT p133</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>Segmentation is the process of breaking an image into groups, based on similarities of the pixels</th></tr></thead><tbody><tr><td>译</td><td>分割是根据像素的相似性将图像分成组的过程</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><img src=/blog/p/intro-to-ai-w3/image/image_zZuuCkOPmQ.png width=934 height=436 srcset="/blog/p/intro-to-ai-w3/image/image_zZuuCkOPmQ_hu_ccd81e93e26114c8.png 480w, /blog/p/intro-to-ai-w3/image/image_zZuuCkOPmQ_hu_7ecfedf642ebb7f.png 1024w" loading=lazy class=gallery-image data-flex-grow=214 data-flex-basis=514px></td></tr></tbody></table></div><hr><h3 id=object-recognition-物体识别>Object Recognition 物体识别</h3><div class=table-wrapper><table><thead><tr><th>概念</th><th>位置</th></tr></thead><tbody><tr><td>Object Recognition 物体识别</td><td>PPT p144<br>Tutorial Solution Q3</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>原</th><th>It is the task of finding and identifying objects in an image or video sequence</th></tr></thead><tbody><tr><td>译</td><td>是在图像或视频序列中寻找和识别物体的任务</td></tr></tbody></table></div><div class=table-wrapper><table><thead><tr><th>说明</th></tr></thead><tbody><tr><td><strong>步骤：</strong><br>Detection – of separate objects<br>Description – of their geometry and positions in 3D<br>Classification – as being one of a known class<br>Identification – of the particular instance<br>Understanding – of spatial relationships between objects<br><br>分离物体的检测在3D中描述它们的几何形状和位置<br>分类为已知类别之一<br>特定实例的标识<br>理解物体之间的空间关系<br><br><strong>应用：</strong><br>It is used in various applications, such as autonomous navigation (recognizing obstacles), augmented reality (overlaying digital information on real-world objects), and robotics (identifying objects for manipulation).<br>它被用于各种应用程序，例如自主导航(识别障碍物)、增强现实(将数字信息覆盖在现实世界的对象上)和机器人(识别用于操作的对象)。</td></tr></tbody></table></div><hr></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/>人工智能导论</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>除非另有声明，本站所有内容以 CC BY-NC-SA 4.0 协议共享</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 Dec 18, 2023 00:00 UTC</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/2025-ml-note/><div class=article-details><h2 class=article-title>机器学习 全四周 概念整理</h2></div></a></article><article><a href=/blog/p/ipn-w3/><div class=article-details><h2 class=article-title>互联网协议 - Week3概念整理</h2></div></a></article><article><a href=/blog/p/ipn-w1/><div class=article-details><h2 class=article-title>互联网协议 - 课程概要 & Week1概念整理</h2></div></a></article><article><a href=/blog/p/java-w1/><div class=article-details><h2 class=article-title>JAVA高级语言程序设计 - Week1概念整理</h2></div></a></article><article><a href=/blog/p/db-hw/><div class=article-details><h2 class=article-title>数据库 - 作业题目 & 实验报告整理</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2023 -
2025 KatMelon's Blog</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>